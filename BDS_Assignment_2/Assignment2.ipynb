{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c95114-fe74-4645-a068-993c5cd70d36",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173ba88c-c5a1-4205-88c3-1ce9c2717dd2",
   "metadata": {},
   "source": [
    "**Group 136**\n",
    "\n",
    "|Name|BITS ID|Contribution|\n",
    "|--|--|--|\n",
    "|Vinayak Nayak|2021fc04135|100%|\n",
    "|Shreysi Kalra|2021fc04586|100%|\n",
    "\n",
    "**Setup Details**\n",
    "\n",
    "- Operating System: Ubuntu 20.04 LTS\n",
    "- Hadoop: Hadoop 3.2.4\n",
    "- Python: Python 3.8\n",
    "- Hive: Hive 3.1.3\n",
    "\n",
    "**Submission Details Summary**\n",
    "\n",
    "- Hadoop is installed and configured in `pseudo-distributed` setup since I have only one node/machine. Hence the default replication factor in the `hdfs-site.xml` is set to `1`. In a real-world distributed scenario we would configure it to be 3/5 i.e. odd number > 1 so that we can achieve fault-tolerance and have a majority quorum in case of network-partition or temporary node-failure etc. \n",
    "- Query 1 is performed using Apache Hive (Which uses Hadoop Map-Reduce as the execution engine beneath it; we haven't configured `tez` or `spark` but use the default `map-reduce` engine for hive)\n",
    "- Queries 2-7 are performed using Hadoop Map-Reduce with the Hadoop Streaming API for Python.\n",
    "- All the outputs are stored in the format `/home/query<#>_output/` which are displayed below in chronological order.\n",
    "- The following videos shows the execution of all our queries with our environment setup and execution engine.\n",
    "    - [Part 1](https://drive.google.com/file/d/1J9GRz_MjjRTp3FbagKYSmC2wVd4Yltk-/view?usp=sharing)\n",
    "    - [Part 2](https://drive.google.com/file/d/1WeUgwBQPE0EmZ7F5X-_VmI6AY2DzhN7n/view?usp=sharing)\n",
    "- The map-reduce code for each of the queries 2-7 is organized in folders with names `query_{#}` respectively.\n",
    "- The commands for creation of table, loading of data from csv and querying for unique customers from `Germany` as the country of our choice is organized in the folder `query_1`.\n",
    "> Each query is executed using python data analysis libraries like numpy and also subsequently using Hadoop map-reduce/ Apache hive. The code for both these methods and the corresponding results are also attached in the document below. Both of these results map which ascertain the veracity of the executed queries.\n",
    "- Configuration files which were modified for utilization of `hadoop` and `hive` are stored in `configuration_files` respectively\n",
    "- Changes made to `.bashrc` file on my setup are reflected in `bashrc` file attached in `configuration_files`. Please note I had to remove other lines of code from the `.bashrc` file to preserve my privacy.\n",
    "- There are some considerations which I had to make made in order to account for some anomalous observations in the dataset. I have mentioned them in the `Data Understanding` module below by doing a quick EDA on the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e14665-6967-4a76-a11a-e6897bd2258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 items\n",
      "drwxr-xr-x   - vinayak supergroup          0 2023-03-04 19:57 /home/query2_output\n",
      "drwxr-xr-x   - vinayak supergroup          0 2023-03-04 19:58 /home/query3_output\n",
      "drwxr-xr-x   - vinayak supergroup          0 2023-03-04 19:59 /home/query4_output\n",
      "drwxr-xr-x   - vinayak supergroup          0 2023-03-04 20:27 /home/query5_output\n",
      "drwxr-xr-x   - vinayak supergroup          0 2023-03-04 20:00 /home/query6_output\n",
      "drwxr-xr-x   - vinayak supergroup          0 2023-03-04 20:22 /home/query7_output\n",
      "drwxr-xr-x   - vinayak supergroup          0 2023-03-04 18:33 /home/vinayak\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the different output files created as a result of map reduce output\n",
    "!hadoop fs -ls /home/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40aa76f-0aed-42c6-a708-95618d52cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 vinayak supergroup   49722977 2023-03-04 17:46 /hdfs_input/assignment2_retail_data_utf8.csv\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the input csv placed in the hadoop file system\n",
    "!hadoop fs -ls /hdfs_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b1cef-9635-47dd-80c6-3fde82b20fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - vinayak supergroup          0 2023-03-05 07:41 /user/hive/warehouse/test.db/retail\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the hive data which has gotten created due to \n",
    "# import of the csv file into hive \n",
    "!hadoop fs -ls /user/hive/warehouse/test.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4eb2c-f237-4753-a974-6011c48ad097",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a2425-6c71-49ad-8a63-d162c1d7935b",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f3efd-e52d-446e-bd0c-15e83fbd4353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record No.</th>\n",
       "      <th>Invoice</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>Price</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>489434</td>\n",
       "      <td>85048</td>\n",
       "      <td>15CM CHRISTMAS GLASS BALL 20 LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>12-01-2009 07:45</td>\n",
       "      <td>6.95</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>489434</td>\n",
       "      <td>79323P</td>\n",
       "      <td>PINK CHERRY LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>12-01-2009 07:45</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Record No. Invoice StockCode                          Description  \\\n",
       "0           1  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS   \n",
       "1           2  489434    79323P                   PINK CHERRY LIGHTS   \n",
       "\n",
       "   Quantity       InvoiceDate  Price  Customer ID         Country  \n",
       "0        12  12-01-2009 07:45   6.95      13085.0  United Kingdom  \n",
       "1        12  12-01-2009 07:45   6.75      13085.0  United Kingdom  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    \"data/Assignment -2  2023 BDS DATA SET online_retail_data.csv\",\n",
    "    encoding=\"unicode_escape\",\n",
    ")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dfcc2f-98aa-4d33-8d66-55a404a7d03e",
   "metadata": {},
   "source": [
    "There are non standard i.e. (not `utf-8`) characters also in our dataframe. This will cause our map reduce jobs to fail as they wouldn't be rendered in our python map-reduce characters. We will have to convert these into utf-8 values. For eg, consider the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ed730-df2f-4ef3-a700-54cd80c89c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31080,491969,gift_0001_80,Dotcomgiftshop Gift Voucher ï¿½80.00,1,12/14/2009 17:57:00,69.56,,United Kingdom\n"
     ]
    }
   ],
   "source": [
    "!sed -ne 31081p data/\"Assignment -2  2023 BDS DATA SET online_retail_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82196b8d-ef3f-4cb7-b0fe-15b90400846e",
   "metadata": {},
   "source": [
    "There is a pound sign in the description which is not getting rendered properly, hence we will have to first convert them into `utf-8` characters before passing them to **map-reduce** tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c6b86-1508-46ee-8a05-497799cfbf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Record No.       int64\n",
       "Invoice         object\n",
       "StockCode       object\n",
       "Description     object\n",
       "Quantity         int64\n",
       "InvoiceDate     object\n",
       "Price          float64\n",
       "Customer ID    float64\n",
       "Country         object\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8c2d2-10b5-45e8-ba16-83c06931ab03",
   "metadata": {},
   "source": [
    "We can see that customer ID has been read as a float. This means there is some issue, let's try to see how many nas are present in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb866f-99b9-4a25-9b01-6367a2c69b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Record No.          0\n",
       "Invoice             0\n",
       "StockCode           0\n",
       "Description      2928\n",
       "Quantity            0\n",
       "InvoiceDate         0\n",
       "Price               0\n",
       "Customer ID    107927\n",
       "Country             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a7bac-d337-4830-a667-7040c63903ff",
   "metadata": {},
   "source": [
    "Since there are null values in `Customer ID` column, they are all read as nans and the column has been made into a float dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006cc58-75f0-4bd2-827f-421037982d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record No.</th>\n",
       "      <th>Invoice</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>Price</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179403</th>\n",
       "      <td>179404</td>\n",
       "      <td>A506401</td>\n",
       "      <td>B</td>\n",
       "      <td>Adjust bad debt</td>\n",
       "      <td>1</td>\n",
       "      <td>04/29/2010 13:36:00</td>\n",
       "      <td>-53594.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276274</th>\n",
       "      <td>276275</td>\n",
       "      <td>A516228</td>\n",
       "      <td>B</td>\n",
       "      <td>Adjust bad debt</td>\n",
       "      <td>1</td>\n",
       "      <td>07/19/2010 11:24:00</td>\n",
       "      <td>-44031.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403472</th>\n",
       "      <td>403473</td>\n",
       "      <td>A528059</td>\n",
       "      <td>B</td>\n",
       "      <td>Adjust bad debt</td>\n",
       "      <td>1</td>\n",
       "      <td>10/20/2010 12:04:00</td>\n",
       "      <td>-38925.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Record No.  Invoice StockCode      Description  Quantity  \\\n",
       "179403      179404  A506401         B  Adjust bad debt         1   \n",
       "276274      276275  A516228         B  Adjust bad debt         1   \n",
       "403472      403473  A528059         B  Adjust bad debt         1   \n",
       "\n",
       "                InvoiceDate     Price  Customer ID         Country  \n",
       "179403  04/29/2010 13:36:00 -53594.36          NaN  United Kingdom  \n",
       "276274  07/19/2010 11:24:00 -44031.79          NaN  United Kingdom  \n",
       "403472  10/20/2010 12:04:00 -38925.87          NaN  United Kingdom  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Price < 0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d8ff1-8e5e-4410-bba3-16d9e5611f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record No.</th>\n",
       "      <th>Invoice</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>Price</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17551</th>\n",
       "      <td>17552</td>\n",
       "      <td>C490798</td>\n",
       "      <td>84997D</td>\n",
       "      <td>PINK 3 PIECE MINI DOTS CUTLERY SET</td>\n",
       "      <td>-6</td>\n",
       "      <td>12-08-2009 11:51</td>\n",
       "      <td>3.75</td>\n",
       "      <td>14277.0</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381112</th>\n",
       "      <td>381113</td>\n",
       "      <td>C526110</td>\n",
       "      <td>22470</td>\n",
       "      <td>HEART OF WICKER LARGE</td>\n",
       "      <td>-1</td>\n",
       "      <td>10-08-2010 13:03</td>\n",
       "      <td>2.55</td>\n",
       "      <td>13113.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442961</th>\n",
       "      <td>442962</td>\n",
       "      <td>C531557</td>\n",
       "      <td>22271</td>\n",
       "      <td>FELTCRAFT DOLL ROSIE</td>\n",
       "      <td>-144</td>\n",
       "      <td>11-09-2010 10:06</td>\n",
       "      <td>2.55</td>\n",
       "      <td>12454.0</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Record No.  Invoice StockCode                         Description  \\\n",
       "17551        17552  C490798    84997D  PINK 3 PIECE MINI DOTS CUTLERY SET   \n",
       "381112      381113  C526110     22470               HEART OF WICKER LARGE   \n",
       "442961      442962  C531557     22271                FELTCRAFT DOLL ROSIE   \n",
       "\n",
       "        Quantity       InvoiceDate  Price  Customer ID         Country  \n",
       "17551         -6  12-08-2009 11:51   3.75      14277.0          France  \n",
       "381112        -1  10-08-2010 13:03   2.55      13113.0  United Kingdom  \n",
       "442961      -144  11-09-2010 10:06   2.55      12454.0           Spain  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Quantity < 0].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ce5b9-51d3-425c-a4ce-e511e6f80ad1",
   "metadata": {},
   "source": [
    "There are negative values in `price` column and `quantity` column which are not actually transactions but some kind of ledger statements from the account or something; we must take this into consideration when using map-reduce on these queries.\n",
    "\n",
    "**Our way of handling**\n",
    "\n",
    "If there is a negative value for quantity or for price, ignore that line item; do not consider it for our analysis.\n",
    "\n",
    "*One more assumption in our analysis is that we're considering the price column as price per unit of the line item mentioned. So our revenue calculations are done after multiplication of quantity with price and then summing across the line items.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a832e-4bd9-4340-88a6-3b3677535720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POST</td>\n",
       "      <td>POSTAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>Discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DOT</td>\n",
       "      <td>DOTCOM POSTAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>Manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C2</td>\n",
       "      <td>CARRIAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BANK CHARGES</td>\n",
       "      <td>Bank Charges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEST001</td>\n",
       "      <td>This is a test product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TEST002</td>\n",
       "      <td>This is a test product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ADJUST</td>\n",
       "      <td>Adjustment by john on 26/01/2010 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GIFT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>m</td>\n",
       "      <td>Manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S</td>\n",
       "      <td>SAMPLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B</td>\n",
       "      <td>Adjust bad debt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ADJUST2</td>\n",
       "      <td>Adjustment by Peter on Jun 25 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AMAZONFEE</td>\n",
       "      <td>AMAZON FEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       StockCode                          Description\n",
       "0           POST                              POSTAGE\n",
       "1              D                             Discount\n",
       "2            DOT                       DOTCOM POSTAGE\n",
       "3              M                               Manual\n",
       "4             C2                             CARRIAGE\n",
       "5   BANK CHARGES                         Bank Charges\n",
       "6        TEST001              This is a test product.\n",
       "7        TEST002              This is a test product.\n",
       "8         ADJUST  Adjustment by john on 26/01/2010 16\n",
       "9           GIFT                                  NaN\n",
       "10             m                               Manual\n",
       "11             S                              SAMPLES\n",
       "12             B                      Adjust bad debt\n",
       "13       ADJUST2  Adjustment by Peter on Jun 25 2010 \n",
       "14            C3                                  NaN\n",
       "15     AMAZONFEE                           AMAZON FEE"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_codes = [\n",
    "    \"ADJUST\", \"ADJUST2\", \"AMAZONFEE\", \"B\", \"BANK CHARGES\", \"C2\", \"C3\", \"D\",\n",
    "    \"DOT\", \"GIFT\", \"M\", \"POST\", \"S\", \"TEST001\", \"TEST002\", \"m\",\n",
    "]\n",
    "\n",
    "df[df.StockCode.isin(stock_codes)].drop_duplicates(subset=[\"StockCode\"])[\n",
    "    [\"StockCode\", \"Description\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45567b6b-ae73-45c0-b814-0d28408edfa8",
   "metadata": {},
   "source": [
    "There are some stock codes which are not actually pertinent to any product but it's related to some accounting/finance details. When writing our queries we will need to skip these test products respectively. As seen above these are clearly not items which are sold but services/miscellaneous things which are dumped in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9a679-51a1-4cdb-8bd9-0f4fedcb2bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dataframe using `utf-8` encoding for our usecase.\n",
    "df.to_csv(\"data/assignment2_retail_data_utf8.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd3bf6-5c21-4094-a09c-490799b700c2",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "Clarification was sought from Professor Sunil Bhutada regarding the file format conversion and permission was granted to consider `utf-8` conversion as mentioned in the `instructor_clarifications` folder of the conversation with the Professor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0e147-8176-4ba3-94a2-3c90cec7d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For local comparisons, make sure to drop these stock code items\n",
    "df = df[~df.StockCode.isin(stock_codes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175573e1-8b93-496b-b171-004c5c23cf31",
   "metadata": {},
   "source": [
    "In the subsequent sections of this document, I have shown the queries and their respective outputs both in Apache ecosystem and in the local ecosystem. The Map-Reduce Job Summary for each of the jobs is attached at the end of the query as requested in the submission requirements respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a812c4b-a735-45e0-96c3-efd253f7e2f5",
   "metadata": {},
   "source": [
    "# Queries \n",
    "**Query 1 Computation**\n",
    "\n",
    "**Total number of unique customers in the \"given country\".**\n",
    "\n",
    "We are considering `given country` as `Germany`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13838a-ad09-4895-816e-27a35278f3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Country == \"Germany\"][\"Customer ID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae71b9b-b76b-42ac-9abb-59dea3037fc5",
   "metadata": {},
   "source": [
    "**Using Hive**\n",
    "\n",
    "```bash\n",
    "# Enter into hive shell\n",
    "cd /home/vinayak/apache-hive-3.1.3-bin\n",
    "\n",
    "bin/hive\n",
    "\n",
    "\n",
    "# Hive commands to create table, load the data and execute the query\n",
    "create table test.retail\n",
    "(\n",
    "record_id int,\n",
    "invoice int,\n",
    "stockcode string,\n",
    "description string,\n",
    "quantity int,\n",
    "invoicedate string,\n",
    "price float,\n",
    "customerid int,\n",
    "country string\n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' STORED AS TEXTFILE;\n",
    "\n",
    "load data local \n",
    "inpath '/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/data/assignment2_retail_data_utf8.csv' \n",
    "into table test.retail;\n",
    "\n",
    "SELECT COUNT(DISTINCT(customerid)) from test.retail WHERE country=\"Germany\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907187d-d7b5-40ac-bdfd-73cd8467683c",
   "metadata": {},
   "source": [
    "![](images/hive_output.png)\n",
    "\n",
    "The summary of the corresponding hive query in map-reduce jobs is as follows.\n",
    "\n",
    "![](images/query1_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584757c4-d67f-4b38-b2bb-42ebf455275b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5c3a3-9cc6-495f-b908-f4b419d8743d",
   "metadata": {},
   "source": [
    "**Query 2 Computation**\n",
    "\n",
    "**Country from which the maximum revenue was collected from sales in the month of March 2010.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8166c-195a-42df-8038-eafeebd43c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b307a6-d75d-4147-931d-3b929c3e00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Month_Year\"] = (\n",
    "    df[\"InvoiceDate\"].dt.month.apply(lambda x: str(x))\n",
    "    + \"/\"\n",
    "    + df[\"InvoiceDate\"].dt.year.apply(lambda x: str(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c96269a-22ca-4f48-95cd-ddace615e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_map = {}\n",
    "for country, sub_df in df[df[\"Month_Year\"] == \"3/2010\"].groupby(by=\"Country\"):\n",
    "    sub_df = sub_df[sub_df.Quantity > 0]\n",
    "    sub_df = sub_df[sub_df.Price > 0]\n",
    "    revenue = (sub_df.Quantity * sub_df.Price).sum()\n",
    "    revenue_map[country] = round(revenue, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811b56e-6f91-4f5b-818f-c1129aef234c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Australia': 429.39, 'Austria': 685.13, 'Bahrain': 548.8, 'Belgium': 629.02, 'Bermuda': 1253.14, 'Channel Islands': 1065.12, 'Cyprus': 2879.19, 'Denmark': 7595.18, 'EIRE': 21778.3, 'France': 8027.59, 'Germany': 15347.08, 'Greece': 522.73, 'Italy': 699.22, 'Japan': 110.4, 'Netherlands': 24241.3, 'Poland': 318.86, 'Portugal': 2399.45, 'Spain': 1456.52, 'Sweden': 1357.58, 'Switzerland': 831.62, 'United Arab Emirates': 1201.52, 'United Kingdom': 670999.26}\n"
     ]
    }
   ],
   "source": [
    "print(revenue_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e74a5e-60ed-4c0d-8dfe-1db6998846ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United Kingdom 670999.26\n"
     ]
    }
   ],
   "source": [
    "highest_revenue_country = sorted(\n",
    "    revenue_map, key=lambda x: revenue_map[x], reverse=True\n",
    ")[0]\n",
    "print(highest_revenue_country, revenue_map[highest_revenue_country])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77039a2-35b1-4b87-ba86-8d0977ee7d53",
   "metadata": {},
   "source": [
    "**Using Hadoop MapReduce**\n",
    "\n",
    "*mapper.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76447f69-d7b5-4fcc-8c12-160c6f7c8ab4",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_2/mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "banned_stock_codes = [\"ADJUST\",\"ADJUST2\",\"AMAZONFEE\",\"B\",\n",
    "                      \"BANK CHARGES\",\"C2\",\"C3\",\"D\",\n",
    "                      \"DOT\",\"GIFT\",\"M\",\n",
    "                      \"POST\",\"S\",\"TEST001\",\"TEST002\",\"m\"]\n",
    "banned_stock_codes = set(banned_stock_codes)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove all the whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Split any given record into corresponding fields\n",
    "    rec_no, invoice, stock_code, *desc, quantity, invoice_date, price,\\\n",
    "    cust_id, country = line.split(\",\")\n",
    "\n",
    "    # We don't want to do any computation for the header of the file, \n",
    "    # hence skip the first line\n",
    "    if not country == \"Country\":\n",
    "        \n",
    "        # Compute the revenue generated\n",
    "        price = float(price); quantity = int(quantity)\n",
    "        revenue = price * quantity\n",
    "        \n",
    "        # Parse the date appropriately\n",
    "        # Some dates are delimited by / and some others are delimited by -\n",
    "        # Some dates have hour-min-sec in time and some others have hour-min\n",
    "        if len(invoice_date.split(\":\")) == 2:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M\")\n",
    "        else:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M:%S\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M:%S\")\n",
    "        \n",
    "        # Only print the dates which belong to the month of March 2010\n",
    "        if (dt.month == 3) and (dt.year == 2010):\n",
    "            # Check if the revenue, quantity and prices are positive\n",
    "            if (price > 0) and (quantity > 0) and (revenue > 0):\n",
    "                # Check if the given stock code is not in the banned stock codes\n",
    "                if stock_code not in banned_stock_codes:\n",
    "                    print(f\"{country},{revenue}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d6907-2b16-48e0-bd30-3165289ce9fd",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "*reducer.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd5f64-f406-40d7-8a2a-539481cf92ac",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_2/reducer.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "country_revenue_map = defaultdict(lambda: 0)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove the leading and trailing whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Parse the mapper input\n",
    "    country, revenue = line.split(',')\n",
    "    \n",
    "    # Sum the revenue into the respective country's account\n",
    "    country_revenue_map[country] += float(revenue)\n",
    "\n",
    "# Figure out the country with highest revenue\n",
    "highest_revenue_country = sorted(country_revenue_map, \\\n",
    "                                 key = lambda x: country_revenue_map[x], \\\n",
    "                                 reverse = True)[0]\n",
    "\n",
    "# Print the highest revenue country and the highest revenue to console\n",
    "print(f\"For 03/2010; Highest Revenue Country: {highest_revenue_country}\\\n",
    "Highest Revenue: {country_revenue_map[highest_revenue_country]:.3f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a1125-e6f2-4177-9ce3-c266e80e7e60",
   "metadata": {},
   "source": [
    "```bash\n",
    "hadoop jar /home/vinayak/hadoop-3.2.4/share/hadoop/tools/lib/hadoop-streaming-3.2.4.jar \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_2/mapper.py \n",
    "-mapper mapper.py \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_2/reducer.py \n",
    "-reducer reducer.py \n",
    "-input /hdfs_input/assignment2_retail_data_utf8.csv \n",
    "-output /home/query2_output/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e01785-ad83-4fab-95b9-40415a8f7dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 03/2010; Highest Revenue Country: United Kingdom | Highest Revenue: 670999.261\t\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /home/query2_output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c0141-73f3-4bb3-97ff-17a4224f3c9e",
   "metadata": {},
   "source": [
    "![](images/query2_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad55bf44-06d7-4cf9-b5a7-01d3bcdcf88f",
   "metadata": {},
   "source": [
    "**Query 3 Computation**\n",
    "\n",
    "**Month of 2010 in which maximum number of items were sold.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e338f44-50ce-42a8-bd3b-d4c01a6a94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = {}\n",
    "for my, sub_df in df.groupby(by=\"Month_Year\"):\n",
    "    sub_df = sub_df[sub_df.Quantity > 0]\n",
    "    sub_df = sub_df[sub_df.Price > 0]\n",
    "    sub_df = sub_df[sub_df.InvoiceDate.dt.year == 2010]\n",
    "    items = sub_df.Quantity.sum()\n",
    "    num_items[my] = round(items, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b3708-8f90-405e-b74e-58598dce48b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2010; Highest Selling Month: 11/2010 | Items Sold: 727556\n"
     ]
    }
   ],
   "source": [
    "highest_selling_month = sorted(num_items, key=lambda x: num_items[x], reverse=True)[0]\n",
    "print(\n",
    "    f\"For 2010; Highest Selling Month: {highest_selling_month} | Items Sold: {num_items[highest_selling_month]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c31b4f0-05b1-4ae9-a5fe-7e73a82135ba",
   "metadata": {},
   "source": [
    "**Using Hadoop MapReduce**\n",
    "\n",
    "*mapper.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8414bd-c326-4489-a93d-ee1d931a5f67",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_3/mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "banned_stock_codes = [\"ADJUST\",\"ADJUST2\",\"AMAZONFEE\",\"B\",\n",
    "                      \"BANK CHARGES\",\"C2\",\"C3\",\"D\",\n",
    "                      \"DOT\",\"GIFT\",\"M\",\n",
    "                      \"POST\",\"S\",\"TEST001\",\"TEST002\",\"m\"]\n",
    "banned_stock_codes = set(banned_stock_codes)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove all the whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Split any given record into corresponding fields\n",
    "    rec_no, invoice, stock_code, *desc, quantity, invoice_date, \\\n",
    "    price, cust_id, country = line.split(\",\")\n",
    "\n",
    "    # We don't want to do any computation for the header of the file, \n",
    "    # hence skip the first line\n",
    "    if not country == \"Country\":\n",
    "        # Cast the price and quantity appropriately\n",
    "        price = float(price); quantity = int(quantity)\n",
    "        \n",
    "        # Parse the date appropriately\n",
    "        # Some dates are delimited by / and some others are delimited by -\n",
    "        # Some dates have hour-min-sec in time and some others have hour-min\n",
    "        if len(invoice_date.split(\":\")) == 2:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M\")\n",
    "        else:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M:%S\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M:%S\")\n",
    "        \n",
    "        # Only print the those transactions which happened in the year 2010\n",
    "        if dt.year == 2010:\n",
    "            # Check if the quantity and prices are positive\n",
    "            if (price > 0) and (quantity > 0):\n",
    "                # Check if given stock code is not in banned stock codes\n",
    "                if not stock_code in banned_stock_codes:\n",
    "                    print(f\"{dt.month},{quantity}\")\n",
    "```                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186851e-1b3e-462e-bbd6-0a2eac06f05e",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "*reducer.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29062a28-9d8c-46a7-99d5-599d00a05ec0",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_3/reducer.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "month_quantity_map = defaultdict(lambda: 0)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove the leading and trailing whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Parse the mapper input\n",
    "    month, quantity = line.split(',')\n",
    "    \n",
    "    # Sum the quantity into the respective month's account\n",
    "    month_quantity_map[month] += int(quantity)\n",
    "\n",
    "# Figure out the month with highest items sold\n",
    "highest_selling_month = sorted(month_quantity_map, key = lambda x: month_quantity_map[x], \\\n",
    "                               reverse = True)[0]\n",
    "\n",
    "# Print the highest revenue country and the highest revenue to console\n",
    "print(f\"For 2010; Highest Selling Month: {highest_selling_month:0<2} | \\\n",
    "Items Sold: {month_quantity_map[highest_selling_month]}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149429e8-13b9-48df-822c-1fbd480b47a3",
   "metadata": {},
   "source": [
    "```bash\n",
    "hadoop jar /home/vinayak/hadoop-3.2.4/share/hadoop/tools/lib/hadoop-streaming-3.2.4.jar \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_3/mapper.py \n",
    "-mapper mapper.py \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_3/reducer.py \n",
    "-reducer reducer.py \n",
    "-input /hdfs_input/assignment2_retail_data_utf8.csv \n",
    "-output /home/query3_output/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74493b42-c56c-4b25-bd7f-758b7497f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2010; Highest Selling Month: 11 | Items Sold: 727556\t\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /home/query3_output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53a063-d256-4e1d-a046-3410d5771212",
   "metadata": {},
   "source": [
    "![](images/query3_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1074d-391d-44b8-96be-4d7d2dec0d75",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbfbee-cbc2-44cd-b937-2de702ea9da1",
   "metadata": {},
   "source": [
    "**Query 4 Computation**\n",
    "\n",
    "**In the month of January 2010, find the country in which maximum number of items were sold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7419499-45c2-4c48-8522-06590c31ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_items = {}\n",
    "for country, sub_df in df[df[\"Month_Year\"] == \"1/2010\"].groupby(by=\"Country\"):\n",
    "    sub_df = sub_df[sub_df.Quantity > 0]\n",
    "    sub_df = sub_df[sub_df.Price > 0]\n",
    "    items = sub_df.Quantity.sum()\n",
    "    country_items[country] = items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671772d-62fb-4eb6-a32f-bc14b4c3fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 01/2010; Country selling max items: United Kingdom | Volume Sold: 257473\n"
     ]
    }
   ],
   "source": [
    "highest_selling_country = sorted(\n",
    "    country_items, key=lambda x: country_items[x], reverse=True\n",
    ")[0]\n",
    "print(\n",
    "    f\"For 01/2010; Country selling max items: {highest_selling_country} | Volume Sold: {country_items[highest_selling_country]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb199ee0-0e98-460b-a187-04d973072204",
   "metadata": {},
   "source": [
    "**Using Hadoop MapReduce**\n",
    "\n",
    "*mapper.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ce31a-6ad4-4ec1-8aa4-f9a0a4879ed2",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_4/mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "banned_stock_codes = [\"ADJUST\",\"ADJUST2\",\"AMAZONFEE\",\"B\",\n",
    "                      \"BANK CHARGES\",\"C2\",\"C3\",\"D\",\n",
    "                      \"DOT\",\"GIFT\",\"M\",\n",
    "                      \"POST\",\"S\",\"TEST001\",\"TEST002\",\"m\"]\n",
    "banned_stock_codes = set(banned_stock_codes)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove all the whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Split any given record into corresponding fields\n",
    "    rec_no, invoice, stock_code, *desc, quantity, invoice_date, \\\n",
    "    price, cust_id, country = line.split(\",\")\n",
    "\n",
    "    # We don't want to do any computation for the header of the file,\n",
    "    # hence skip the first line\n",
    "    if not country == \"Country\":\n",
    "        \n",
    "        price = float(price); quantity = int(quantity)\n",
    "        \n",
    "        # Parse the date appropriately\n",
    "        # Some dates are delimited by / and some others are delimited by -\n",
    "        # Some dates have hour-min-sec in time and some others have hour-min\n",
    "        if len(invoice_date.split(\":\")) == 2:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M\")\n",
    "        else:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M:%S\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M:%S\")\n",
    "        \n",
    "        # Only select the dates which belong to the month of January 2010\n",
    "        if (dt.month == 1) and (dt.year == 2010):\n",
    "            # Check if the quantity and prices are positive\n",
    "            if (price > 0) and (quantity > 0):\n",
    "                # Check if the stock code is not in the banned stock codes\n",
    "                if stock_code not in banned_stock_codes:\n",
    "                    print(f\"{country},{quantity}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff75a40-d0fa-4c0f-a4a3-efc40e6fdcd2",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "*reducer.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d87750-317e-45c8-ad83-f1dd9cc83fc3",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_4/reducer.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "country_quantity_map = defaultdict(lambda: 0)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove the leading and trailing whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Parse the mapper input\n",
    "    country, quantity = line.split(',')\n",
    "    \n",
    "    # Sum the revenue into the respective country's account\n",
    "    country_quantity_map[country] += int(quantity)\n",
    "\n",
    "# Figure out the country with highest quantity of items sold\n",
    "highest_selling_country = sorted(country_quantity_map, key = lambda x: country_quantity_map[x], \\\n",
    "                                 reverse = True)[0]\n",
    "\n",
    "print(f\"For 01/2010; Country selling max items: {highest_selling_country}\\\n",
    "| Volume Sold: {country_quantity_map[highest_selling_country]}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc173069-5268-4709-8cf4-331a5be8e5d1",
   "metadata": {},
   "source": [
    "```bash\n",
    "hadoop jar /home/vinayak/hadoop-3.2.4/share/hadoop/tools/lib/hadoop-streaming-3.2.4.jar \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_4/mapper.py \n",
    "-mapper mapper.py \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_4/reducer.py \n",
    "-reducer reducer.py \n",
    "-input /hdfs_input/assignment2_retail_data_utf8.csv \n",
    "-output /home/query4_output/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0b025-33d0-48bf-bb31-4c1aa3a9c0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 01/2010; Country selling max items: United Kingdom | Volume Sold: 257473\t\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /home/query4_output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e1c34a-9c3b-46de-a21c-6c50d764ff01",
   "metadata": {},
   "source": [
    "![](images/query4_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a6f2a-bac6-4e49-b6b7-fe70dfd932cb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2729b76a-d226-4d44-bbef-4a81257ca312",
   "metadata": {},
   "source": [
    "**Query 5 Computation**\n",
    "\n",
    "**The StockCode of the item with the highest number of sales in the \"given country\" in the year 2010**\n",
    "\n",
    "We are considering `given country` as `Germany`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f3b24-322b-41ff-9806-be9eaa34a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_code_sales = {}\n",
    "for stock_code, sub_df in df[\n",
    "    (df.InvoiceDate.dt.year == 2010) & (df.Country == \"Germany\")\n",
    "].groupby(by=\"StockCode\"):\n",
    "    sub_df = sub_df[sub_df.Quantity > 0]\n",
    "    sub_df = sub_df[sub_df.Price > 0]\n",
    "    sales = sub_df.Quantity.sum()\n",
    "    stock_code_sales[stock_code] = sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff8485-0bc1-4901-acd2-73e875a882a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Germany; Stock code with highest sale: 22326 | Volume Sold: 1543\n"
     ]
    }
   ],
   "source": [
    "highest_sale_item = sorted(\n",
    "    stock_code_sales, key=lambda x: stock_code_sales[x], reverse=True\n",
    ")[0]\n",
    "print(\n",
    "    f\"For Germany; Stock code with highest sale: {highest_sale_item} | Volume Sold: {stock_code_sales[highest_sale_item]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35cb3a-6b1d-4555-8a4b-dedb6f5ace91",
   "metadata": {},
   "source": [
    "**Using Hadoop MapReduce**\n",
    "\n",
    "*mapper.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb9511-dd4c-49af-bbc6-9502c5ab4cfa",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_5/mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "banned_stock_codes = [\"ADJUST\",\"ADJUST2\",\"AMAZONFEE\",\"B\",\n",
    "                      \"BANK CHARGES\",\"C2\",\"C3\",\"D\",\n",
    "                      \"DOT\",\"GIFT\",\"M\",\n",
    "                      \"POST\",\"S\",\"TEST001\",\"TEST002\",\"m\"]\n",
    "banned_stock_codes = set(banned_stock_codes)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove all the whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Split any given record into corresponding fields\n",
    "    rec_no, invoice, stock_code, *desc, quantity, invoice_date, price, \\\n",
    "    cust_id, country = line.split(\",\")\n",
    "\n",
    "    # We only want to consider Germany's sales\n",
    "    if country == \"Germany\":\n",
    "        \n",
    "        price = float(price); quantity = int(quantity)\n",
    "        \n",
    "        # Parse the date appropriately\n",
    "        # Some dates are delimited by / and some others are delimited by -\n",
    "        # Some dates have hour-min-sec in time and some others have hour-min\n",
    "        if len(invoice_date.split(\":\")) == 2:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M\")\n",
    "        else:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M:%S\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M:%S\")\n",
    "        \n",
    "        # Only select the dates which belong to the month of December 2010\n",
    "        if (dt.year == 2010):\n",
    "            # Check if the quantity and prices are positive\n",
    "            if (price > 0) and (quantity > 0):\n",
    "                # Check if the stock code is not in the banned stock codes\n",
    "                if stock_code not in banned_stock_codes:\n",
    "                    print(f\"{stock_code},{quantity}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b66fa6-70f1-4576-9815-c10f8d1a8bcb",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "*reducer.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864277f-1d43-41f1-ac8f-6640366d59a8",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_5/reducer.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "stock_code_sales = defaultdict(lambda: 0)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove the leading and trailing whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Parse the mapper input\n",
    "    stock_code, quantity = line.split(',')\n",
    "    \n",
    "    # Sum the revenue into the respective country's account\n",
    "    stock_code_sales[stock_code] += int(quantity)\n",
    "\n",
    "# Figure out the country with highest quantity of items sold\n",
    "highest_sale_item = sorted(stock_code_sales, key = lambda x: stock_code_sales[x], \\\n",
    "                           reverse = True)[0]\n",
    "\n",
    "print(f\"For Germany; Stock Code giving highest sale: {highest_sale_item} \\\n",
    "| Volume Sold: {stock_code_sales[highest_sale_item]:.2f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29666438-47a3-46e9-852b-d42c8b141667",
   "metadata": {},
   "source": [
    "```bash\n",
    "hadoop jar /home/vinayak/hadoop-3.2.4/share/hadoop/tools/lib/hadoop-streaming-3.2.4.jar \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_5/mapper.py \n",
    "-mapper mapper.py \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_5/reducer.py \n",
    "-reducer reducer.py \n",
    "-input /hdfs_input/assignment2_retail_data_utf8.csv \n",
    "-output /home/query5_output/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c5073-0cdf-485a-9928-87988bec31eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Germany; Stock Code giving highest sale: 22326 | Volume Sold: 1543.00\t\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /home/query5_output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a0dfdb-2bc5-4aa5-9261-996d68100b5d",
   "metadata": {},
   "source": [
    "![](images/query5_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96faabe-6e46-48cd-9116-f0aaae80bef2",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae0ff0-b7b1-4bce-bd03-c5d4f899daac",
   "metadata": {},
   "source": [
    "**Query 6 Computation**\n",
    "\n",
    "**StockCode of the item for which the maximum revenue was received by sales in the month of December 2010.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06089c-3b09-4230-92f7-59f50a576be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_revenue_map = {}\n",
    "for stock_code, sub_df in df[df[\"Month_Year\"] == \"12/2010\"].groupby(by=\"StockCode\"):\n",
    "    sub_df = sub_df[sub_df.Quantity > 0]\n",
    "    sub_df = sub_df[sub_df.Price > 0]\n",
    "    revenue = (sub_df.Quantity * sub_df.Price).sum()\n",
    "    stock_revenue_map[stock_code] = round(revenue, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cfd0d-b89d-452a-80c9-e9bee12b36f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 12/2010; Stock Code giving highest revenue: 22423 | Revenue Accrued: 13478.98\n"
     ]
    }
   ],
   "source": [
    "highest_revenue_item = sorted(\n",
    "    stock_revenue_map, key=lambda x: stock_revenue_map[x], reverse=True\n",
    ")[0]\n",
    "print(\n",
    "    f\"For 12/2010; Stock Code giving highest revenue: {highest_revenue_item} | Revenue Accrued: {stock_revenue_map[highest_revenue_item]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b50e3b-247f-433d-bf58-a47d3caef672",
   "metadata": {},
   "source": [
    "**Using Hadoop MapReduce**\n",
    "\n",
    "*mapper.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc312279-6f93-445b-bba9-dc8997e6db02",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_6/mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "banned_stock_codes = [\"ADJUST\",\"ADJUST2\",\"AMAZONFEE\",\"B\",\n",
    "                      \"BANK CHARGES\",\"C2\",\"C3\",\"D\",\n",
    "                      \"DOT\",\"GIFT\",\"M\",\n",
    "                      \"POST\",\"S\",\"TEST001\",\"TEST002\",\"m\"]\n",
    "banned_stock_codes = set(banned_stock_codes)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove all the whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Split any given record into corresponding fields\n",
    "    rec_no, invoice, stock_code, *desc, quantity, invoice_date, price, \\\n",
    "    cust_id, country = line.split(\",\")\n",
    "\n",
    "    # We don't want to do any computation for the header of the file, \n",
    "    # hence skip the first line\n",
    "    if not country == \"Country\":\n",
    "        \n",
    "        price = float(price); quantity = int(quantity)\n",
    "        revenue = price * quantity\n",
    "        \n",
    "        # Parse the date appropriately\n",
    "        # Some dates are delimited by / and some others are delimited by -\n",
    "        # Some dates have hour-min-sec in time and some others have hour-min\n",
    "        if len(invoice_date.split(\":\")) == 2:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M\")\n",
    "        else:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M:%S\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M:%S\")\n",
    "        \n",
    "        # Only select the dates which belong to the month of December 2010\n",
    "        if (dt.month == 12) and (dt.year == 2010):\n",
    "            # Check if the quantity and prices are positive\n",
    "            if (price > 0) and (quantity > 0) and (revenue > 0):\n",
    "                # Check if the stock code is not in the banned stock codes\n",
    "                if stock_code not in banned_stock_codes:\n",
    "                    print(f\"{stock_code},{revenue}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef51f8a-3550-4029-956d-99b9bfdf8c41",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "*reducer.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cff7ef-3d83-48a9-bb17-510f23c93ff6",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_6/reducer.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "stock_revenue_map = defaultdict(lambda: 0)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove the leading and trailing whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Parse the mapper input\n",
    "    stock_code, revenue = line.split(',')\n",
    "    \n",
    "    # Sum the revenue into the respective country's account\n",
    "    stock_revenue_map[stock_code] += float(revenue)\n",
    "\n",
    "# Figure out the country with highest quantity of items sold\n",
    "highest_revenue_item = sorted(stock_revenue_map, key = lambda x: stock_revenue_map[x], \\\n",
    "                              reverse = True)[0]\n",
    "\n",
    "print(f\"For 12/2010; Stock Code giving highest revenue: {highest_revenue_item} \\\n",
    "| Revenue Accrued: {stock_revenue_map[highest_revenue_item]:.2f}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29db1b-16c5-47bc-9557-177bc384508e",
   "metadata": {},
   "source": [
    "```bash\n",
    "hadoop jar /home/vinayak/hadoop-3.2.4/share/hadoop/tools/lib/hadoop-streaming-3.2.4.jar \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_6/mapper.py \n",
    "-mapper mapper.py \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_6/reducer.py \n",
    "-reducer reducer.py \n",
    "-input /hdfs_input/assignment2_retail_data_utf8.csv \n",
    "-output /home/query6_output/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892bdfdd-bec8-4c07-8049-9ac8f1f60839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 12/2010; Stock Code giving highest revenue: 22423 | Revenue Accrued: 13478.98\t\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /home/query6_output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0fd32a-9398-459b-bfc8-331b42269733",
   "metadata": {},
   "source": [
    "![](images/query6_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660bfdfd-80ac-437f-b1e0-24ef71d02218",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pagebreak\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a81884-af7a-4d61-9328-c61d688d0909",
   "metadata": {},
   "source": [
    "**Query 7 Computation**\n",
    "\n",
    "**The country in which minimum number of sales happened in 2010.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e1372-daa3-4286-9459-f152e4e1c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_sales = {}\n",
    "for country, sub_df in df[df.InvoiceDate.dt.year == 2010].groupby(by=\"Country\"):\n",
    "    sub_df = sub_df[sub_df.Quantity > 0]\n",
    "    sub_df = sub_df[sub_df.Price > 0]\n",
    "    sales = sub_df.Quantity.sum()\n",
    "    country_sales[country] = round(sales, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f259f5-e9ab-4be4-ae1d-9c85d1d232cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2010, Country with lowest quantity sales: Lebanon | Total items sold: 72\n"
     ]
    }
   ],
   "source": [
    "lowest_2010_sales_country = sorted(\n",
    "    country_sales, key=lambda x: country_sales[x], reverse=False\n",
    ")[0]\n",
    "print(\n",
    "    f\"For 2010, Country with lowest quantity sales: {lowest_2010_sales_country} | Total items sold: {country_sales[lowest_2010_sales_country]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d020502-e45a-40de-b616-d94e0bb6c497",
   "metadata": {},
   "source": [
    "**Using Hadoop MapReduce**\n",
    "\n",
    "*mapper.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7da0f-38bc-412a-8d2a-2f5a91aa98f9",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_7/mapper.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "banned_stock_codes = [\"ADJUST\",\"ADJUST2\",\"AMAZONFEE\",\"B\",\n",
    "                      \"BANK CHARGES\",\"C2\",\"C3\",\"D\",\n",
    "                      \"DOT\",\"GIFT\",\"M\",\n",
    "                      \"POST\",\"S\",\"TEST001\",\"TEST002\",\"m\"]\n",
    "banned_stock_codes = set(banned_stock_codes)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove all the whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Split any given record into corresponding fields\n",
    "    rec_no, invoice, stock_code, *desc, quantity, invoice_date, price,\\\n",
    "    cust_id, country = line.split(\",\")\n",
    "\n",
    "    # We don't want to do any computation for the header of the file, \n",
    "    # hence skip the first line\n",
    "    if not country == \"Country\":\n",
    "        \n",
    "        price = float(price); quantity = int(quantity)\n",
    "        revenue = price * quantity\n",
    "        \n",
    "        # Parse the date appropriately\n",
    "        # Some dates are delimited by / and some others are delimited by -\n",
    "        # Some dates have hour-min-sec in time and some others have hour-min\n",
    "        if len(invoice_date.split(\":\")) == 2:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M\")\n",
    "        else:\n",
    "            if \"/\" in invoice_date:\n",
    "                dt = datetime.strptime(invoice_date, \"%m/%d/%Y %H:%M:%S\")\n",
    "            else:\n",
    "                dt = datetime.strptime(invoice_date, \"%m-%d-%Y %H:%M:%S\")\n",
    "        \n",
    "        # Only select the dates which belong to the year 2010\n",
    "        if dt.year == 2010:\n",
    "            # Check if the quantity and prices are positive\n",
    "            if (price > 0) and (quantity > 0):\n",
    "                # Check if the stock code is not in the banned stock codes\n",
    "                if stock_code not in banned_stock_codes:\n",
    "                    print(f\"{country},{quantity}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a279217f-ab3e-4463-91f9-7bcea264e113",
   "metadata": {},
   "source": [
    "*reducer.py*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde31472-e983-4fe7-acf2-ee6731bd7e6f",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/home/vinayak/anaconda3/bin/python\n",
    "\"\"\"/home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_7/reducer.py\"\"\"\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "country_sales_map = defaultdict(lambda: 0)\n",
    "\n",
    "# Read the input from standard input\n",
    "for line in sys.stdin:\n",
    "    # Remove the leading and trailing whitespaces\n",
    "    line = line.strip()\n",
    "\n",
    "    # Parse the mapper input\n",
    "    country, quantity = line.split(',')\n",
    "    \n",
    "    # Sum the revenue into the respective country's account\n",
    "    country_sales_map[country] += int(quantity)\n",
    "\n",
    "# Figure out the country with highest quantity of items sold\n",
    "lowest_sales_item = sorted(country_sales_map, key = lambda x: country_sales_map[x],\\\n",
    "                           reverse = False)[0]\n",
    "\n",
    "print(f\"For the year 2010; Country with lowest quantity of sales: {lowest_sales_item} \\\n",
    "| Total items sold: {country_sales_map[lowest_sales_item]:.2f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c9420-f790-4eff-9f79-9cbe8c2e7bbe",
   "metadata": {},
   "source": [
    "Execute the hadoop map-reduce job\n",
    "\n",
    "```bash\n",
    "hadoop jar /home/vinayak/hadoop-3.2.4/share/hadoop/tools/lib/hadoop-streaming-3.2.4.jar \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_7/mapper.py \n",
    "-mapper mapper.py \n",
    "-file /home/vinayak/Desktop/PGM_BDS_Assignment/BDS_Assignment_2/query_7/reducer.py \n",
    "-reducer reducer.py \n",
    "-input /hdfs_input/assignment2_retail_data_utf8.csv \n",
    "-output /home/query7_output/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c61748-41ae-4139-ba9f-32eb94060acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the year 2010; Country with lowest quantity of sales: Lebanon | Total items sold: 72.00\t\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /home/query7_output/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29704c29-188e-460b-8c71-67a611d20f5a",
   "metadata": {},
   "source": [
    "![](images/query7_summary.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
